{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed4ad02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa19a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Chrome options for running in headless mode\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Enable headless mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3239d25b",
   "metadata": {},
   "source": [
    "# 1.Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details: \n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9017587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 30 Youtube vidoe details to be scrapped\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Views (In Billions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>12.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[16]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[17]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[18]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[21]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[26]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Wheels on the Bus\"[27]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[28]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[29]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[30]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[35]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[36]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[38]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Roar\"[39]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Sorry\"[41]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[42]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Thinking Out Loud\"[43]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[44]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Dark Horse\"[45]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[46]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Faded\"[47]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Perfect\"[48]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"[49]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Girls Like You\"[50]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[51]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Lean On\"[52]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Bailando\"[53]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[6]   \n",
       "1    2.                                   \"Despacito\"[9]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[16]   \n",
       "3    4.                                  \"Bath Song\"[17]   \n",
       "4    5.                               \"Shape of You\"[18]   \n",
       "5    6.                              \"See You Again\"[21]   \n",
       "6    7.                \"Phonics Song with Two Words\"[26]   \n",
       "7    8.                          \"Wheels on the Bus\"[27]   \n",
       "8    9.                                \"Uptown Funk\"[28]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[29]   \n",
       "10  11.                              \"Gangnam Style\"[30]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[35]   \n",
       "12  13.                             \"Dame Tu Cosita\"[36]   \n",
       "13  14.                                     \"Axel F\"[37]   \n",
       "14  15.                                      \"Sugar\"[38]   \n",
       "15  16.                                       \"Roar\"[39]   \n",
       "16  17.                             \"Counting Stars\"[40]   \n",
       "17  18.                                      \"Sorry\"[41]   \n",
       "18  19.                        \"Baa Baa Black Sheep\"[42]   \n",
       "19  20.                          \"Thinking Out Loud\"[43]   \n",
       "20  21.           \"Waka Waka (This Time for Africa)\"[44]   \n",
       "21  22.                                 \"Dark Horse\"[45]   \n",
       "22  23.                             \"Lakdi Ki Kathi\"[46]   \n",
       "23  24.                                      \"Faded\"[47]   \n",
       "24  25.                                    \"Perfect\"[48]   \n",
       "25  26.                                 \"Let Her Go\"[49]   \n",
       "26  27.                             \"Girls Like You\"[50]   \n",
       "27  28.          \"Humpty the train on a fruits ride\"[51]   \n",
       "28  29.                                    \"Lean On\"[52]   \n",
       "29  30.                                   \"Bailando\"[53]   \n",
       "\n",
       "                                           Artist     Published Date  \\\n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                      Luis Fonsi   January 12, 2017   \n",
       "2                                     LooLoo Kids    October 8, 2016   \n",
       "3                      Cocomelon – Nursery Rhymes        May 2, 2018   \n",
       "4                                      Ed Sheeran   January 30, 2017   \n",
       "5                                     Wiz Khalifa      April 6, 2015   \n",
       "6                                       ChuChu TV      March 6, 2014   \n",
       "7                      Cocomelon – Nursery Rhymes       May 24, 2018   \n",
       "8                                     Mark Ronson  November 19, 2014   \n",
       "9                                     Miroshka TV  February 27, 2018   \n",
       "10                                            Psy      July 15, 2012   \n",
       "11                                     Get Movies   January 31, 2012   \n",
       "12                                      El Chombo      April 5, 2018   \n",
       "13                                     Crazy Frog      June 16, 2009   \n",
       "14                                       Maroon 5   January 14, 2015   \n",
       "15                                     Katy Perry  September 5, 2013   \n",
       "16                                    OneRepublic       May 31, 2013   \n",
       "17                                  Justin Bieber   October 22, 2015   \n",
       "18                     Cocomelon – Nursery Rhymes      June 25, 2018   \n",
       "19                                     Ed Sheeran    October 7, 2014   \n",
       "20                                        Shakira       June 4, 2010   \n",
       "21                                     Katy Perry  February 20, 2014   \n",
       "22                                   Jingle Toons      June 14, 2018   \n",
       "23                                    Alan Walker   December 3, 2015   \n",
       "24                                     Ed Sheeran   November 9, 2017   \n",
       "25                                      Passenger      July 25, 2012   \n",
       "26                                       Maroon 5       May 31, 2018   \n",
       "27  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "28                                    Major Lazer     March 22, 2015   \n",
       "29                               Enrique Iglesias     April 11, 2014   \n",
       "\n",
       "   Views (In Billions)  \n",
       "0                12.85  \n",
       "1                 8.16  \n",
       "2                 6.70  \n",
       "3                 6.20  \n",
       "4                 6.00  \n",
       "5                 5.89  \n",
       "6                 5.30  \n",
       "7                 5.24  \n",
       "8                 4.92  \n",
       "9                 4.89  \n",
       "10                4.80  \n",
       "11                4.55  \n",
       "12                4.35  \n",
       "13                3.91  \n",
       "14                3.87  \n",
       "15                3.80  \n",
       "16                3.79  \n",
       "17                3.66  \n",
       "18                3.64  \n",
       "19                3.60  \n",
       "20                3.59  \n",
       "21                3.52  \n",
       "22                3.48  \n",
       "23                3.45  \n",
       "24                3.45  \n",
       "25                3.44  \n",
       "26                3.42  \n",
       "27                3.41  \n",
       "28                3.38  \n",
       "29                3.38  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# Open the given URL\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n",
    "\n",
    "# Find the table that contains the video details\n",
    "table = driver.find_element(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]')\n",
    "\n",
    "# Find the body of table in order to extract rows present in the table body\n",
    "tbody = table.find_element(By.TAG_NAME,'tbody')\n",
    "\n",
    "# Extract all rows present in the body. \n",
    "rows = tbody.find_elements(By.TAG_NAME,'tr')\n",
    "\n",
    "print(\"Top\",len(rows),\"Youtube vidoe details to be scrapped\")#Print total no of data present.\n",
    "\n",
    "\n",
    "## initialize empty lists for the details to be scrapped like : rank, name, artist, date, view\n",
    "ranks=[]\n",
    "names=[]\n",
    "artists=[]\n",
    "dates=[]\n",
    "views=[]\n",
    "\n",
    "try:  \n",
    "    for row in rows: #iterate through every row \n",
    "        columns = row.find_elements(By.TAG_NAME,'td') # find all column data in every row\n",
    "        if len(columns)>=6:  #no of columns in each row is 6. \n",
    "            \n",
    "            rank = columns[0].text  # scrapping the required data \n",
    "            name = columns[1].text\n",
    "            artist =columns[2].text\n",
    "            date = columns[4].text\n",
    "            view = columns[3].text\n",
    "        \n",
    "        \n",
    "           # append all the scrapped to the lists defined. \n",
    "            ranks.append(rank)  \n",
    "            names.append(name)\n",
    "            artists.append(artist)\n",
    "            dates.append(date)\n",
    "            views.append(view)\n",
    "\n",
    "except NoSuchElementException:  ## handling NoSuchElementException\n",
    "    print(\"ERROR\")\n",
    "    pass\n",
    "        \n",
    "\n",
    "# close the driver\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "## Put the data into a dictionary\n",
    "top30_df = {\"Rank\":ranks,\n",
    "           \"Name\":names,\n",
    "           \"Artist\":artists,\n",
    "           \"Published Date\": dates,\n",
    "           \"Views (In Billions)\":views}\n",
    "\n",
    "# Convert the dictonary to a dataframe \n",
    "df = pd.DataFrame(top30_df)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7028b9ae",
   "metadata": {},
   "source": [
    "# 2. Scrape the details team India’s international fixtures from bcci.tv. Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73434b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of data available:  16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur, Dhaka</td>\n",
       "      <td>9 JUL 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur, Dhaka</td>\n",
       "      <td>11 JUL 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Windsor Park, Dominica</td>\n",
       "      <td>12 JUL 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur, Dhaka</td>\n",
       "      <td>13 JUL 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur, Dhaka</td>\n",
       "      <td>16 JUL 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur, Dhaka</td>\n",
       "      <td>19 JUL 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Queen's Park Oval, Trinidad</td>\n",
       "      <td>20 JUL 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur, Dhaka</td>\n",
       "      <td>22 JUL 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Kensington Oval, Barbados</td>\n",
       "      <td>27 JUL 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Kensington Oval, Barbados</td>\n",
       "      <td>29 JUL 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Brian Lara Stadium, Trinidad</td>\n",
       "      <td>1 AUG 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Brian Lara Stadium, Trinidad</td>\n",
       "      <td>3 AUG 2023</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>National Stadium, Guyana</td>\n",
       "      <td>6 AUG 2023</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>National Stadium, Guyana</td>\n",
       "      <td>8 AUG 2023</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4th T20I</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Central Broward Regional Park Stadium Turf Gr...</td>\n",
       "      <td>12 AUG 2023</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5th T20I</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Central Broward Regional Park Stadium Turf Gr...</td>\n",
       "      <td>13 AUG 2023</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Match_title                               Series  \\\n",
       "0    1st T20I   INDIA WOMEN TOUR OF BANGLADESH 2023   \n",
       "1    2nd T20I   INDIA WOMEN TOUR OF BANGLADESH 2023   \n",
       "2    1st Test        INDIA TOUR OF WEST INDIES 2023   \n",
       "3    3rd T20I   INDIA WOMEN TOUR OF BANGLADESH 2023   \n",
       "4     1st ODI   INDIA WOMEN TOUR OF BANGLADESH 2023   \n",
       "5     2nd ODI   INDIA WOMEN TOUR OF BANGLADESH 2023   \n",
       "6    2nd Test        INDIA TOUR OF WEST INDIES 2023   \n",
       "7     3rd ODI   INDIA WOMEN TOUR OF BANGLADESH 2023   \n",
       "8     1st ODI        INDIA TOUR OF WEST INDIES 2023   \n",
       "9     2nd ODI        INDIA TOUR OF WEST INDIES 2023   \n",
       "10    3rd ODI        INDIA TOUR OF WEST INDIES 2023   \n",
       "11   1st T20I        INDIA TOUR OF WEST INDIES 2023   \n",
       "12   2nd T20I        INDIA TOUR OF WEST INDIES 2023   \n",
       "13   3rd T20I        INDIA TOUR OF WEST INDIES 2023   \n",
       "14   4th T20I        INDIA TOUR OF WEST INDIES 2023   \n",
       "15   5th T20I        INDIA TOUR OF WEST INDIES 2023   \n",
       "\n",
       "                                                Place         Date  \\\n",
       "0        Shere Bangla National Stadium, Mirpur, Dhaka   9 JUL 2023   \n",
       "1        Shere Bangla National Stadium, Mirpur, Dhaka  11 JUL 2023   \n",
       "2                              Windsor Park, Dominica  12 JUL 2023   \n",
       "3        Shere Bangla National Stadium, Mirpur, Dhaka  13 JUL 2023   \n",
       "4        Shere Bangla National Stadium, Mirpur, Dhaka  16 JUL 2023   \n",
       "5        Shere Bangla National Stadium, Mirpur, Dhaka  19 JUL 2023   \n",
       "6                         Queen's Park Oval, Trinidad  20 JUL 2023   \n",
       "7        Shere Bangla National Stadium, Mirpur, Dhaka  22 JUL 2023   \n",
       "8                           Kensington Oval, Barbados  27 JUL 2023   \n",
       "9                           Kensington Oval, Barbados  29 JUL 2023   \n",
       "10                       Brian Lara Stadium, Trinidad   1 AUG 2023   \n",
       "11                       Brian Lara Stadium, Trinidad   3 AUG 2023   \n",
       "12                           National Stadium, Guyana   6 AUG 2023   \n",
       "13                           National Stadium, Guyana   8 AUG 2023   \n",
       "14   Central Broward Regional Park Stadium Turf Gr...  12 AUG 2023   \n",
       "15   Central Broward Regional Park Stadium Turf Gr...  13 AUG 2023   \n",
       "\n",
       "           Time  \n",
       "0   1:30 PM IST  \n",
       "1   1:30 PM IST  \n",
       "2   7:30 PM IST  \n",
       "3   1:30 PM IST  \n",
       "4   9:00 AM IST  \n",
       "5   9:00 AM IST  \n",
       "6   7:30 PM IST  \n",
       "7   9:00 AM IST  \n",
       "8   7:00 PM IST  \n",
       "9   7:00 PM IST  \n",
       "10  7:00 PM IST  \n",
       "11  8:00 PM IST  \n",
       "12  8:00 PM IST  \n",
       "13  8:00 PM IST  \n",
       "14  8:00 PM IST  \n",
       "15  8:00 PM IST  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the Chrome driver\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)  ## running chrome in headless mode\n",
    "\n",
    "# Navigate to the BCCI website\n",
    "driver.get(\"https://www.bcci.tv/\")\n",
    "\n",
    "# Find and click the \"International Fixtures\" link\n",
    "\n",
    "driver.execute_script(\"arguments[0].click();\", driver.find_element(By.XPATH, \"//*[@id='navigation']/ul[1]/li[2]/a\"))\n",
    "\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# Find more elements button and click \n",
    "\n",
    "driver.execute_script(\"arguments[0].click();\", driver.find_element(By.XPATH, '//button[@class=\"match-btn btn-red d-flex align-items-center justify-content-center mx-auto mt-3\"]'))\n",
    "\n",
    "# Find the elements containing the fixture details\n",
    "\n",
    "main = driver.find_element(By.XPATH,'//div[@class=\"fixture-tab-inner row\"]')\n",
    "\n",
    "# Find all elements in main\n",
    "cards = main.find_elements(By.XPATH,'//div[@class=\"col-lg-4 col-md-6 col-sm-12 ng-scope\"]')\n",
    "\n",
    "print(\"No of data available: \", len(cards))\n",
    "# Initialize empty lists to store the details\n",
    "international_fixtures=[]\n",
    "match_titles = []\n",
    "series = []\n",
    "places = []\n",
    "dates = []\n",
    "times = []\n",
    "\n",
    "try:\n",
    "    # Extract the details from each fixture element\n",
    "    for element in cards:\n",
    " \n",
    "       series_name_element = element.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "    \n",
    "       place_element = element.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]')\n",
    "    \n",
    "       date_element = element.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "    \n",
    "       time_element = element.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## append the scrapped data\n",
    "    for i in range(len(series_name_element)):\n",
    "   \n",
    "        series = series_name_element[i].text\n",
    "        palces = place_element[i].text.split(\"-\")[1]\n",
    "        dates = date_element[i].text\n",
    "        times=time_element[i].text\n",
    "        match_titles = place_element[i].text.split(\"-\")[0]\n",
    "        \n",
    "        \n",
    "        international_fixtures.append([match_titles,series,palces,dates,times])\n",
    "        \n",
    "except NoSuchElementException:  ##handles no such element exception. \n",
    "    pass\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "## Display the data in a dataframe. \n",
    "International_fixtures = pd.DataFrame(international_fixtures,columns=['Match_title','Series','Place','Date',\n",
    "                                   'Time'])\n",
    "    \n",
    "International_fixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c81999",
   "metadata": {},
   "source": [
    "# 3.Scrape the details of State-wise GDP of India from statisticstime.com. Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "776da009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 datas are presented in the GDP by Indian States table.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(19-20)Current Prices</th>\n",
       "      <th>GSDP(18-19)Current Prices</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(19-20)Current Prices  \\\n",
       "0     1                Maharashtra                         -   \n",
       "1     2                 Tamil Nadu                 1,845,853   \n",
       "2     3              Uttar Pradesh                 1,687,818   \n",
       "3     4                    Gujarat                         -   \n",
       "4     5                  Karnataka                 1,631,977   \n",
       "5     6                West Bengal                 1,253,832   \n",
       "6     7                  Rajasthan                 1,020,989   \n",
       "7     8             Andhra Pradesh                   972,782   \n",
       "8     9                  Telangana                   969,604   \n",
       "9    10             Madhya Pradesh                   906,672   \n",
       "10   11                     Kerala                         -   \n",
       "11   12                      Delhi                   856,112   \n",
       "12   13                    Haryana                   831,610   \n",
       "13   14                      Bihar                   611,804   \n",
       "14   15                     Punjab                   574,760   \n",
       "15   16                     Odisha                   521,275   \n",
       "16   17                      Assam                         -   \n",
       "17   18               Chhattisgarh                   329,180   \n",
       "18   19                  Jharkhand                   328,598   \n",
       "19   20                Uttarakhand                         -   \n",
       "20   21            Jammu & Kashmir                         -   \n",
       "21   22           Himachal Pradesh                   165,472   \n",
       "22   23                        Goa                    80,449   \n",
       "23   24                    Tripura                    55,984   \n",
       "24   25                 Chandigarh                         -   \n",
       "25   26                 Puducherry                    38,253   \n",
       "26   27                  Meghalaya                    36,572   \n",
       "27   28                     Sikkim                    32,496   \n",
       "28   29                    Manipur                    31,790   \n",
       "29   30                   Nagaland                         -   \n",
       "30   31          Arunachal Pradesh                         -   \n",
       "31   32                    Mizoram                    26,503   \n",
       "32   33  Andaman & Nicobar Islands                         -   \n",
       "\n",
       "   GSDP(18-19)Current Prices Share(18-19) GDP($billion)  \n",
       "0                  2,632,792       13.94%       399.921  \n",
       "1                  1,630,208        8.63%       247.629  \n",
       "2                  1,584,764        8.39%       240.726  \n",
       "3                  1,502,899        7.96%       228.290  \n",
       "4                  1,493,127        7.91%       226.806  \n",
       "5                  1,089,898        5.77%       165.556  \n",
       "6                    942,586        4.99%       143.179  \n",
       "7                    862,957        4.57%       131.083  \n",
       "8                    861,031        4.56%       130.791  \n",
       "9                    809,592        4.29%       122.977  \n",
       "10                   781,653        4.14%       118.733  \n",
       "11                   774,870        4.10%       117.703  \n",
       "12                   734,163        3.89%       111.519  \n",
       "13                   530,363        2.81%        80.562  \n",
       "14                   526,376        2.79%        79.957  \n",
       "15                   487,805        2.58%        74.098  \n",
       "16                   315,881        1.67%        47.982  \n",
       "17                   304,063        1.61%        46.187  \n",
       "18                   297,204        1.57%        45.145  \n",
       "19                   245,895        1.30%        37.351  \n",
       "20                   155,956        0.83%        23.690  \n",
       "21                   153,845        0.81%        23.369  \n",
       "22                    73,170        0.39%        11.115  \n",
       "23                    49,845        0.26%         7.571  \n",
       "24                    42,114        0.22%         6.397  \n",
       "25                    34,433        0.18%         5.230  \n",
       "26                    33,481        0.18%         5.086  \n",
       "27                    28,723        0.15%         4.363  \n",
       "28                    27,870        0.15%         4.233  \n",
       "29                    27,283        0.14%         4.144  \n",
       "30                    24,603        0.13%         3.737  \n",
       "31                    22,287        0.12%         3.385  \n",
       "32                         -            -             -  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the Chrome driver\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)  ## running chrome in headless mode\n",
    "\n",
    "# Navigate to the Statisticstimes website\n",
    "driver.get(\"https://statisticstimes.com\")\n",
    "\n",
    "# Find and click the \"Economy\" link\n",
    "\n",
    "driver.execute_script(\"arguments[0].click();\", driver.find_element(By.XPATH, '//*[@id=\"top\"]/div[2]/div[2]/div/a[3]'))\n",
    "\n",
    "## find and click GDP by Indian States\n",
    "\n",
    "driver.execute_script(\"arguments[0].click();\", driver.find_element(By.LINK_TEXT, \"» GDP of Indian states\"))\n",
    "\n",
    "## find all the rows containing the required details\n",
    "rows = driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]//tbody//tr[@role=\"row\"]')\n",
    "\n",
    "print(len(rows),\"datas are presented in the GDP by Indian States table.\")\n",
    "\n",
    "## Initialising an empty list\n",
    "data=[]\n",
    "\n",
    "## Before iterating handle nOsuch element exception.\n",
    "\n",
    "try:\n",
    "    for row in rows: ## Iterate through every row.\n",
    "        cols = row.find_elements(By.TAG_NAME,\"td\") # find column data of every row.\n",
    "        cols =[col.text.strip() for col in cols[:6]] #scrape evey data \n",
    "        data.append(cols) # append the scrapped data into the list. \n",
    "\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "# close the driver\n",
    "driver.quit()\n",
    "\n",
    "# Display the scrapped data into dataframe\n",
    "GDP = pd.DataFrame(data,columns=['Rank','State','GSDP(19-20)Current Prices','GSDP(18-19)Current Prices',\n",
    "                                 'Share(18-19)','GDP($billion)'])\n",
    "GDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d967a74e",
   "metadata": {},
   "source": [
    "# 4. Scrape the details of trending repositories on Github.com. Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af11dfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of Trending repositories in Github :  25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_ffbb8_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Title</th>\n",
       "      <th class=\"col_heading level0 col1\" >Description</th>\n",
       "      <th class=\"col_heading level0 col2\" >Language</th>\n",
       "      <th class=\"col_heading level0 col3\" >URL</th>\n",
       "      <th class=\"col_heading level0 col4\" >contributors_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ffbb8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ffbb8_row0_col0\" class=\"data row0 col0\" >XingangPan / DragGAN</td>\n",
       "      <td id=\"T_ffbb8_row0_col1\" class=\"data row0 col1\" >Official Code for DragGAN (SIGGRAPH 2023)</td>\n",
       "      <td id=\"T_ffbb8_row0_col2\" class=\"data row0 col2\" >Python</td>\n",
       "      <td id=\"T_ffbb8_row0_col3\" class=\"data row0 col3\" ><a target=\"_blank\" href=\"https://github.com/XingangPan/DragGAN\">https://github.com/XingangPan/DragGAN</a></td>\n",
       "      <td id=\"T_ffbb8_row0_col4\" class=\"data row0 col4\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffbb8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ffbb8_row1_col0\" class=\"data row1 col0\" >THUDM / ChatGLM2-6B</td>\n",
       "      <td id=\"T_ffbb8_row1_col1\" class=\"data row1 col1\" >ChatGLM2-6B: An Open Bilingual Chat LLM | 开源双语对话语言模型</td>\n",
       "      <td id=\"T_ffbb8_row1_col2\" class=\"data row1 col2\" >Python</td>\n",
       "      <td id=\"T_ffbb8_row1_col3\" class=\"data row1 col3\" ><a target=\"_blank\" href=\"https://github.com/THUDM/ChatGLM2-6B\">https://github.com/THUDM/ChatGLM2-6B</a></td>\n",
       "      <td id=\"T_ffbb8_row1_col4\" class=\"data row1 col4\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffbb8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ffbb8_row2_col0\" class=\"data row2 col0\" >CASIA-IVA-Lab / FastSAM</td>\n",
       "      <td id=\"T_ffbb8_row2_col1\" class=\"data row2 col1\" >Fast Segment Anything</td>\n",
       "      <td id=\"T_ffbb8_row2_col2\" class=\"data row2 col2\" >Python</td>\n",
       "      <td id=\"T_ffbb8_row2_col3\" class=\"data row2 col3\" ><a target=\"_blank\" href=\"https://github.com/CASIA-IVA-Lab/FastSAM\">https://github.com/CASIA-IVA-Lab/FastSAM</a></td>\n",
       "      <td id=\"T_ffbb8_row2_col4\" class=\"data row2 col4\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffbb8_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ffbb8_row3_col0\" class=\"data row3 col0\" >ramonvc / freegpt-webui</td>\n",
       "      <td id=\"T_ffbb8_row3_col1\" class=\"data row3 col1\" >GPT 3.5/4 with a Chat Web UI. No API key required.</td>\n",
       "      <td id=\"T_ffbb8_row3_col2\" class=\"data row3 col2\" >Python</td>\n",
       "      <td id=\"T_ffbb8_row3_col3\" class=\"data row3 col3\" ><a target=\"_blank\" href=\"https://github.com/ramonvc/freegpt-webui\">https://github.com/ramonvc/freegpt-webui</a></td>\n",
       "      <td id=\"T_ffbb8_row3_col4\" class=\"data row3 col4\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffbb8_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ffbb8_row4_col0\" class=\"data row4 col0\" >embedchain / embedchain</td>\n",
       "      <td id=\"T_ffbb8_row4_col1\" class=\"data row4 col1\" >Framework to easily create LLM powered bots over any dataset.</td>\n",
       "      <td id=\"T_ffbb8_row4_col2\" class=\"data row4 col2\" >Python</td>\n",
       "      <td id=\"T_ffbb8_row4_col3\" class=\"data row4 col3\" ><a target=\"_blank\" href=\"https://github.com/embedchain/embedchain\">https://github.com/embedchain/embedchain</a></td>\n",
       "      <td id=\"T_ffbb8_row4_col4\" class=\"data row4 col4\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffbb8_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_ffbb8_row5_col0\" class=\"data row5 col0\" >spacedriveapp / spacedrive</td>\n",
       "      <td id=\"T_ffbb8_row5_col1\" class=\"data row5 col1\" >Spacedrive is an open source cross-platform file explorer, powered by a virtual distributed filesystem written in Rust.</td>\n",
       "      <td id=\"T_ffbb8_row5_col2\" class=\"data row5 col2\" >Rust</td>\n",
       "      <td id=\"T_ffbb8_row5_col3\" class=\"data row5 col3\" ><a target=\"_blank\" href=\"https://github.com/spacedriveapp/spacedrive\">https://github.com/spacedriveapp/spacedrive</a></td>\n",
       "      <td id=\"T_ffbb8_row5_col4\" class=\"data row5 col4\" >64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffbb8_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_ffbb8_row6_col0\" class=\"data row6 col0\" >xitanggg / open-resume</td>\n",
       "      <td id=\"T_ffbb8_row6_col1\" class=\"data row6 col1\" >OpenResume is a powerful open-source resume builder and resume parser. https://open-resume.com/</td>\n",
       "      <td id=\"T_ffbb8_row6_col2\" class=\"data row6 col2\" >TypeScript</td>\n",
       "      <td id=\"T_ffbb8_row6_col3\" class=\"data row6 col3\" ><a target=\"_blank\" href=\"https://github.com/xitanggg/open-resume\">https://github.com/xitanggg/open-resume</a></td>\n",
       "      <td id=\"T_ffbb8_row6_col4\" class=\"data row6 col4\" >-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffbb8_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_ffbb8_row7_col0\" class=\"data row7 col0\" >papers-we-love / papers-we-love</td>\n",
       "      <td id=\"T_ffbb8_row7_col1\" class=\"data row7 col1\" >Papers from the computer science community to read and discuss.</td>\n",
       "      <td id=\"T_ffbb8_row7_col2\" class=\"data row7 col2\" >Shell</td>\n",
       "      <td id=\"T_ffbb8_row7_col3\" class=\"data row7 col3\" ><a target=\"_blank\" href=\"https://github.com/papers-we-love/papers-we-love\">https://github.com/papers-we-love/papers-we-love</a></td>\n",
       "      <td id=\"T_ffbb8_row7_col4\" class=\"data row7 col4\" >247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffbb8_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_ffbb8_row8_col0\" class=\"data row8 col0\" >sadmann7 / skateshop</td>\n",
       "      <td id=\"T_ffbb8_row8_col1\" class=\"data row8 col1\" >An open source e-commerce skateshop build with everything new in Next.js 13.</td>\n",
       "      <td id=\"T_ffbb8_row8_col2\" class=\"data row8 col2\" >TypeScript</td>\n",
       "      <td id=\"T_ffbb8_row8_col3\" class=\"data row8 col3\" ><a target=\"_blank\" href=\"https://github.com/sadmann7/skateshop\">https://github.com/sadmann7/skateshop</a></td>\n",
       "      <td id=\"T_ffbb8_row8_col4\" class=\"data row8 col4\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffbb8_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_ffbb8_row9_col0\" class=\"data row9 col0\" >microsoft / Web-Dev-For-Beginners</td>\n",
       "      <td id=\"T_ffbb8_row9_col1\" class=\"data row9 col1\" >24 Lessons, 12 Weeks, Get Started as a Web Developer</td>\n",
       "      <td id=\"T_ffbb8_row9_col2\" class=\"data row9 col2\" >JavaScript</td>\n",
       "      <td id=\"T_ffbb8_row9_col3\" class=\"data row9 col3\" ><a target=\"_blank\" href=\"https://github.com/microsoft/Web-Dev-For-Beginners\">https://github.com/microsoft/Web-Dev-For-Beginners</a></td>\n",
       "      <td id=\"T_ffbb8_row9_col4\" class=\"data row9 col4\" >205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffbb8_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_ffbb8_row10_col0\" class=\"data row10 col0\" >sb-ocr / diy-spacemouse</td>\n",
       "      <td id=\"T_ffbb8_row10_col1\" class=\"data row10 col1\" >A DIY navigation device for Fusion360</td>\n",
       "      <td id=\"T_ffbb8_row10_col2\" class=\"data row10 col2\" >C++</td>\n",
       "      <td id=\"T_ffbb8_row10_col3\" class=\"data row10 col3\" ><a target=\"_blank\" href=\"https://github.com/sb-ocr/diy-spacemouse\">https://github.com/sb-ocr/diy-spacemouse</a></td>\n",
       "      <td id=\"T_ffbb8_row10_col4\" class=\"data row10 col4\" >-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffbb8_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_ffbb8_row11_col0\" class=\"data row11 col0\" >THUDM / ChatGLM-6B</td>\n",
       "      <td id=\"T_ffbb8_row11_col1\" class=\"data row11 col1\" >ChatGLM-6B: An Open Bilingual Dialogue Language Model | 开源双语对话语言模型</td>\n",
       "      <td id=\"T_ffbb8_row11_col2\" class=\"data row11 col2\" >Python</td>\n",
       "      <td id=\"T_ffbb8_row11_col3\" class=\"data row11 col3\" ><a target=\"_blank\" href=\"https://github.com/THUDM/ChatGLM-6B\">https://github.com/THUDM/ChatGLM-6B</a></td>\n",
       "      <td id=\"T_ffbb8_row11_col4\" class=\"data row11 col4\" >44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffbb8_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_ffbb8_row12_col0\" class=\"data row12 col0\" >SizheAn / PanoHead</td>\n",
       "      <td id=\"T_ffbb8_row12_col1\" class=\"data row12 col1\" >Code Repository for CVPR 2023 Paper \"PanoHead: Geometry-Aware 3D Full-Head Synthesis in 360 degree\"</td>\n",
       "      <td id=\"T_ffbb8_row12_col2\" class=\"data row12 col2\" >Python</td>\n",
       "      <td id=\"T_ffbb8_row12_col3\" class=\"data row12 col3\" ><a target=\"_blank\" href=\"https://github.com/SizheAn/PanoHead\">https://github.com/SizheAn/PanoHead</a></td>\n",
       "      <td id=\"T_ffbb8_row12_col4\" class=\"data row12 col4\" >-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffbb8_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_ffbb8_row13_col0\" class=\"data row13 col0\" >PlexPt / awesome-chatgpt-prompts-zh</td>\n",
       "      <td id=\"T_ffbb8_row13_col1\" class=\"data row13 col1\" >ChatGPT 中文调教指南。各种场景使用指南。学习怎么让它听你的话。</td>\n",
       "      <td id=\"T_ffbb8_row13_col2\" class=\"data row13 col2\" >_</td>\n",
       "      <td id=\"T_ffbb8_row13_col3\" class=\"data row13 col3\" ><a target=\"_blank\" href=\"https://github.com/PlexPt/awesome-chatgpt-prompts-zh\">https://github.com/PlexPt/awesome-chatgpt-prompts-zh</a></td>\n",
       "      <td id=\"T_ffbb8_row13_col4\" class=\"data row13 col4\" >19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffbb8_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_ffbb8_row14_col0\" class=\"data row14 col0\" >firstcontributions / first-contributions</td>\n",
       "      <td id=\"T_ffbb8_row14_col1\" class=\"data row14 col1\" >🚀✨ Help beginners to contribute to open source projects</td>\n",
       "      <td id=\"T_ffbb8_row14_col2\" class=\"data row14 col2\" >_</td>\n",
       "      <td id=\"T_ffbb8_row14_col3\" class=\"data row14 col3\" ><a target=\"_blank\" href=\"https://github.com/firstcontributions/first-contributions\">https://github.com/firstcontributions/first-contributions</a></td>\n",
       "      <td id=\"T_ffbb8_row14_col4\" class=\"data row14 col4\" >5,000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffbb8_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_ffbb8_row15_col0\" class=\"data row15 col0\" >actualbudget / actual</td>\n",
       "      <td id=\"T_ffbb8_row15_col1\" class=\"data row15 col1\" >A local-first personal finance system</td>\n",
       "      <td id=\"T_ffbb8_row15_col2\" class=\"data row15 col2\" >JavaScript</td>\n",
       "      <td id=\"T_ffbb8_row15_col3\" class=\"data row15 col3\" ><a target=\"_blank\" href=\"https://github.com/actualbudget/actual\">https://github.com/actualbudget/actual</a></td>\n",
       "      <td id=\"T_ffbb8_row15_col4\" class=\"data row15 col4\" >52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffbb8_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_ffbb8_row16_col0\" class=\"data row16 col0\" >xtekky / gpt4free</td>\n",
       "      <td id=\"T_ffbb8_row16_col1\" class=\"data row16 col1\" >The official gpt4free repository | various collection of powerful language models</td>\n",
       "      <td id=\"T_ffbb8_row16_col2\" class=\"data row16 col2\" >Python</td>\n",
       "      <td id=\"T_ffbb8_row16_col3\" class=\"data row16 col3\" ><a target=\"_blank\" href=\"https://github.com/xtekky/gpt4free\">https://github.com/xtekky/gpt4free</a></td>\n",
       "      <td id=\"T_ffbb8_row16_col4\" class=\"data row16 col4\" >83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffbb8_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_ffbb8_row17_col0\" class=\"data row17 col0\" >sveltejs / svelte</td>\n",
       "      <td id=\"T_ffbb8_row17_col1\" class=\"data row17 col1\" >Cybernetically enhanced web apps</td>\n",
       "      <td id=\"T_ffbb8_row17_col2\" class=\"data row17 col2\" >JavaScript</td>\n",
       "      <td id=\"T_ffbb8_row17_col3\" class=\"data row17 col3\" ><a target=\"_blank\" href=\"https://github.com/sveltejs/svelte\">https://github.com/sveltejs/svelte</a></td>\n",
       "      <td id=\"T_ffbb8_row17_col4\" class=\"data row17 col4\" >610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffbb8_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_ffbb8_row18_col0\" class=\"data row18 col0\" >OpenGVLab / DragGAN</td>\n",
       "      <td id=\"T_ffbb8_row18_col1\" class=\"data row18 col1\" >Unofficial Implementation of DragGAN - \"Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold\" （DragGAN 全功能实现，在线Demo，本地部署试用，代码、模型已全部开源，支持Windows, macOS, Linux）</td>\n",
       "      <td id=\"T_ffbb8_row18_col2\" class=\"data row18 col2\" >Python</td>\n",
       "      <td id=\"T_ffbb8_row18_col3\" class=\"data row18 col3\" ><a target=\"_blank\" href=\"https://github.com/OpenGVLab/DragGAN\">https://github.com/OpenGVLab/DragGAN</a></td>\n",
       "      <td id=\"T_ffbb8_row18_col4\" class=\"data row18 col4\" >9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffbb8_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_ffbb8_row19_col0\" class=\"data row19 col0\" >OpenDriveLab / UniAD</td>\n",
       "      <td id=\"T_ffbb8_row19_col1\" class=\"data row19 col1\" >[CVPR 2023 Best Paper] Planning-oriented Autonomous Driving</td>\n",
       "      <td id=\"T_ffbb8_row19_col2\" class=\"data row19 col2\" >Python</td>\n",
       "      <td id=\"T_ffbb8_row19_col3\" class=\"data row19 col3\" ><a target=\"_blank\" href=\"https://github.com/OpenDriveLab/UniAD\">https://github.com/OpenDriveLab/UniAD</a></td>\n",
       "      <td id=\"T_ffbb8_row19_col4\" class=\"data row19 col4\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffbb8_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_ffbb8_row20_col0\" class=\"data row20 col0\" >qgis / QGIS</td>\n",
       "      <td id=\"T_ffbb8_row20_col1\" class=\"data row20 col1\" >QGIS is a free, open source, cross platform (lin/win/mac) geographical information system (GIS)</td>\n",
       "      <td id=\"T_ffbb8_row20_col2\" class=\"data row20 col2\" >C++</td>\n",
       "      <td id=\"T_ffbb8_row20_col3\" class=\"data row20 col3\" ><a target=\"_blank\" href=\"https://github.com/qgis/QGIS\">https://github.com/qgis/QGIS</a></td>\n",
       "      <td id=\"T_ffbb8_row20_col4\" class=\"data row20 col4\" >491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffbb8_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_ffbb8_row21_col0\" class=\"data row21 col0\" >chat2db / Chat2DB</td>\n",
       "      <td id=\"T_ffbb8_row21_col1\" class=\"data row21 col1\" >🔥 🔥 🔥 An intelligent and versatile general-purpose SQL client and reporting tool for databases which integrates ChatGPT capabilities.(智能的通用数据库SQL客户端和报表工具)</td>\n",
       "      <td id=\"T_ffbb8_row21_col2\" class=\"data row21 col2\" >Java</td>\n",
       "      <td id=\"T_ffbb8_row21_col3\" class=\"data row21 col3\" ><a target=\"_blank\" href=\"https://github.com/chat2db/Chat2DB\">https://github.com/chat2db/Chat2DB</a></td>\n",
       "      <td id=\"T_ffbb8_row21_col4\" class=\"data row21 col4\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffbb8_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_ffbb8_row22_col0\" class=\"data row22 col0\" >Kanaries / pygwalker</td>\n",
       "      <td id=\"T_ffbb8_row22_col1\" class=\"data row22 col1\" >PyGWalker: Turn your pandas dataframe into a Tableau-style User Interface for visual analysis</td>\n",
       "      <td id=\"T_ffbb8_row22_col2\" class=\"data row22 col2\" >Python</td>\n",
       "      <td id=\"T_ffbb8_row22_col3\" class=\"data row22 col3\" ><a target=\"_blank\" href=\"https://github.com/Kanaries/pygwalker\">https://github.com/Kanaries/pygwalker</a></td>\n",
       "      <td id=\"T_ffbb8_row22_col4\" class=\"data row22 col4\" >11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffbb8_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_ffbb8_row23_col0\" class=\"data row23 col0\" >ggerganov / ggml</td>\n",
       "      <td id=\"T_ffbb8_row23_col1\" class=\"data row23 col1\" >Tensor library for machine learning</td>\n",
       "      <td id=\"T_ffbb8_row23_col2\" class=\"data row23 col2\" >C</td>\n",
       "      <td id=\"T_ffbb8_row23_col3\" class=\"data row23 col3\" ><a target=\"_blank\" href=\"https://github.com/ggerganov/ggml\">https://github.com/ggerganov/ggml</a></td>\n",
       "      <td id=\"T_ffbb8_row23_col4\" class=\"data row23 col4\" >48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffbb8_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_ffbb8_row24_col0\" class=\"data row24 col0\" >StanGirard / quivr</td>\n",
       "      <td id=\"T_ffbb8_row24_col1\" class=\"data row24 col1\" >🧠 Dump all your files and thoughts into your private GenerativeAI Second Brain and chat with it 🧠</td>\n",
       "      <td id=\"T_ffbb8_row24_col2\" class=\"data row24 col2\" >TypeScript</td>\n",
       "      <td id=\"T_ffbb8_row24_col3\" class=\"data row24 col3\" ><a target=\"_blank\" href=\"https://github.com/StanGirard/quivr\">https://github.com/StanGirard/quivr</a></td>\n",
       "      <td id=\"T_ffbb8_row24_col4\" class=\"data row24 col4\" >28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fdc1c7b26d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Set the Chrome driver , run in headless mode.\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "## Handling WebDriverException taht occured , as the website's load is real slow \n",
    "max_retries = 3 ##no of maximum retries\n",
    "retry_delay = 2 ## retry dealy wait \n",
    "for retry in range(max_retries): \n",
    "    try:\n",
    "        ## Find and click Top 100 songs\n",
    "        driver.get(\"https://github.com/\")\n",
    "        \n",
    "        break\n",
    "        \n",
    "    except WebDriverException as e: ## Handle the exception\n",
    "        print(\"WebDriverException occurred on retry\", retry + 1)\n",
    "        print(\"Retrying in\", retry_delay, \"seconds...\")\n",
    "        time.sleep(retry_delay)\n",
    "else:\n",
    "    # If all retries fail, handle the exception\n",
    "    print(\"All retries failed. WebDriverException could not be resolved , Please Check your internet connection\")\n",
    "\n",
    "driver.execute_script(\"arguments[0].click();\", driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a'))\n",
    "\n",
    "## Hold on the driver to find and select the Box containing the element\n",
    "wait = WebDriverWait(driver, 10)\n",
    "wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"article.Box-row\")))\n",
    "\n",
    "## Find all boxes. \n",
    "boxes = driver.find_elements(By.CSS_SELECTOR, \"article.Box-row\")\n",
    "\n",
    "print(\"Total no of Trending repositories in Github : \",len(boxes))\n",
    "\n",
    "## Initialise and empty list\n",
    "data=[]\n",
    "\n",
    "\n",
    "for box in boxes:\n",
    "    \n",
    "    g_data={} ## define an empty dictonary\n",
    "    \n",
    "    try:\n",
    "        titles = box.find_element(By.XPATH,'.//h2[@class=\"h3 lh-condensed\"]').text.strip(\"/\")\n",
    "    except NoSuchElementException:\n",
    "        titles=\"-\"  ## scrapping titles \n",
    "    \n",
    "    try:\n",
    "        des= box.find_element(By.XPATH,'.//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]').text.strip()\n",
    "    except NoSuchElementException:\n",
    "        des=\"-\"  ## scrapping description\n",
    "    \n",
    "    try:\n",
    "        lan = box.find_element(By.XPATH,'.//span[@itemprop=\"programmingLanguage\"]').text.strip()\n",
    "    except NoSuchElementException:\n",
    "        lan =\"_\" ## scrapping language\n",
    "    \n",
    "    try:\n",
    "        ## To scrap CONTRIBUTORS COUNT , it is not presnet in the main page,  Steps followed : \n",
    "        \n",
    "        ## Step 1 : Find Urls for every repository and open them in a new window \n",
    "        url = box.find_element(By.XPATH,'.//h2[@class=\"h3 lh-condensed\"]//a').get_attribute(\"href\")\n",
    "        \n",
    "        driver.execute_script(f\"window.open('{url}', '_blank');\")\n",
    "        \n",
    "        ## Switch Driver source to the new window \n",
    "        driver.switch_to.window(driver.window_handles[1])\n",
    "        \n",
    "        try: \n",
    "            ## Find all the elements presented in the side page\n",
    "            x=driver.find_elements(By.XPATH,'//h2[@class=\"h4 mb-3\"]')\n",
    "            ## Out of the lists of elements select COntributors Count. \n",
    "            count = x[-2].text.split('\\n')[1]  ## For most of the links Contributors COunt is the second to last column.\n",
    "        \n",
    "           \n",
    "        except:\n",
    "            try:\n",
    "                count= x[-1].text.split('\\n')[1] ## for Few links Contributors Count is the last column. \n",
    "            except:\n",
    "                count =\"-\"\n",
    "        \n",
    "        ## Close the new window\n",
    "        driver.close()\n",
    "        ## Switch Back to the first window \n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        \n",
    "        \n",
    "    except:\n",
    "         continue\n",
    "    \n",
    "    ## append all the scrapped details \n",
    "    g_data[\"Title\"] =titles\n",
    "    g_data[\"Description\"]=des\n",
    "    g_data[\"Language\"] = lan\n",
    "    g_data[\"URL\"]=url\n",
    "    g_data[\"contributors_count\"]=count\n",
    "    \n",
    "    data.append(g_data)\n",
    "\n",
    "## Close the main driver.\n",
    "driver.close()\n",
    "\n",
    "## Display the data in Dataframe\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "## Make the URLs Clickable in dataframe\n",
    "def make_clickable(val):\n",
    "    # target _blank to open new window\n",
    "    return '<a target=\"_blank\" href=\"{}\">{}</a>'.format(val, val)\n",
    "\n",
    "## display dataframe\n",
    "data.style.format({'URL': make_clickable})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403198f0",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artistname\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "746065c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Last_Week_Rank</th>\n",
       "      <th>Peak_Rank</th>\n",
       "      <th>Weeks_on_Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Fast Car</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Calm Down</td>\n",
       "      <td>Rema &amp; Selena Gomez</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>All My Life</td>\n",
       "      <td>Lil Durk Featuring J. Cole</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Angel, Pt. 1</td>\n",
       "      <td>Kodak Black, NLE Choppa, Jimin, JVKE &amp; Muni Long</td>\n",
       "      <td>-</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Girl In Mine</td>\n",
       "      <td>Parmalee</td>\n",
       "      <td>-</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Moonlight</td>\n",
       "      <td>Kali Uchis</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Classy 101</td>\n",
       "      <td>Feid x Young Miko</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Bluffin</td>\n",
       "      <td>Gucci Mane &amp; Lil Baby</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank          Song                                            Artist  \\\n",
       "0     1    Last Night                                     Morgan Wallen   \n",
       "1     2      Fast Car                                        Luke Combs   \n",
       "2     3     Calm Down                               Rema & Selena Gomez   \n",
       "3     4       Flowers                                       Miley Cyrus   \n",
       "4     5   All My Life                        Lil Durk Featuring J. Cole   \n",
       "..  ...           ...                                               ...   \n",
       "95   96  Angel, Pt. 1  Kodak Black, NLE Choppa, Jimin, JVKE & Muni Long   \n",
       "96   97  Girl In Mine                                          Parmalee   \n",
       "97   98     Moonlight                                        Kali Uchis   \n",
       "98   99    Classy 101                                 Feid x Young Miko   \n",
       "99  100       Bluffin                             Gucci Mane & Lil Baby   \n",
       "\n",
       "   Last_Week_Rank Peak_Rank Weeks_on_Board  \n",
       "0               1         1             21  \n",
       "1               3         2             13  \n",
       "2               4         3             42  \n",
       "3               2         1             23  \n",
       "4               5         2              6  \n",
       "..            ...       ...            ...  \n",
       "95              -        65              2  \n",
       "96              -        97              1  \n",
       "97             90        80             11  \n",
       "98              -        99              1  \n",
       "99              -       100              1  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Set up Chrome driver and run in headless mode. \n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "## Navigate to Billboard.com\n",
    "driver.get(\"https://www.billboard.com\")\n",
    "\n",
    "## Find and click on Charts Option.\n",
    "driver.execute_script(\"arguments[0].click();\",driver.find_element(By.XPATH,'//*[@id=\"main-wrapper\"]/header/div/div[2]/div/div/div[1]/div[1]/button/span'))\n",
    "\n",
    "## Handling WebDriverException that occured as, the website's load is real slow \n",
    "max_retries = 3 ##no of maximum retries\n",
    "retry_delay = 2 ## retry dealy wait \n",
    "for retry in range(max_retries): \n",
    "    try:\n",
    "        ## Find and click Top 100 songs\n",
    "        driver.execute_script(\"arguments[0].click();\",driver.find_element(By.XPATH,'//*[@id=\"main-wrapper\"]/div[9]/div/div/div/ul/li[1]/ul/li[2]/a'))\n",
    "        \n",
    "        break\n",
    "        \n",
    "    except WebDriverException as e: ## Handle the exception\n",
    "        print(\"WebDriverException occurred on retry\", retry + 1)\n",
    "        print(\"Retrying in\", retry_delay, \"seconds...\")\n",
    "        time.sleep(retry_delay)\n",
    "else:\n",
    "    # If all retries fail, handle the exception\n",
    "    print(\"All retries failed. WebDriverException could not be resolved.\")\n",
    "\n",
    "\n",
    "## Find and select all element conatining conatiners.\n",
    "boxes = driver.find_elements(By.CSS_SELECTOR, \"div.o-chart-results-list-row-container\")\n",
    "\n",
    "## initialise empty lists for storage.\n",
    "ranks =[]\n",
    "songs=[]\n",
    "artists=[]\n",
    "last_week_ranks=[]\n",
    "peak_ranks=[]\n",
    "weeks_on_board=[]\n",
    "\n",
    "##Iterate through every element box.\n",
    "for box in boxes:\n",
    "    try: \n",
    "        ## Scrap the details\n",
    "        rank = box.find_element(By.XPATH,'.//span[@class=\"c-label  a-font-primary-bold-l u-font-size-32@tablet u-letter-spacing-0080@tablet\"]').text\n",
    "        \n",
    "        details= box.find_elements(By.XPATH,'.//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]//li')\n",
    "\n",
    "        if len(details)>=12:\n",
    "            song_name = details[0].text.split('\\n')[0]\n",
    "            artist = details[0].text.split('\\n')[1]\n",
    "            last_wr =details[3].text\n",
    "            peak_r = details[4].text\n",
    "            weeks_ob= details[5].text\n",
    "            \n",
    "            # store the scrapped details\n",
    "            songs.append(song_name)\n",
    "            artists.append(artist)\n",
    "            last_week_ranks.append(last_wr)\n",
    "            peak_ranks.append(peak_r)\n",
    "            weeks_on_board.append(weeks_ob)\n",
    "        \n",
    "        ranks.append(rank)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "## Close the driver\n",
    "driver.quit()\n",
    "\n",
    "## Store the details in dictonary\n",
    "billboard_hot_100={\"Rank\":ranks,\n",
    "                  \"Song\":songs,\n",
    "                  \"Artist\":artists,\n",
    "                  \"Last_Week_Rank\":last_week_ranks,\n",
    "                  \"Peak_Rank\":peak_ranks,\n",
    "                  \"Weeks_on_Board\":weeks_on_board}\n",
    "## Display the data in dataframe\n",
    "\n",
    "df =pd.DataFrame(billboard_hot_100)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7861fcc",
   "metadata": {},
   "source": [
    "# 6. Scrape the details of Highest sellingnovels. \n",
    "## Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Book name B) Author name C) Volumes sold D) Publisher E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e2229f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume_Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume_Sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Set up Chrome browser in headless mode\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "## Get the required link\n",
    "\n",
    "## Handling WebDriverException taht occured , as the website's load is real slow \n",
    "max_retries = 3 ##no of maximum retries\n",
    "retry_delay = 2 ## retry dealy wait \n",
    "for retry in range(max_retries): \n",
    "    try:\n",
    "        ## Find and click Top 100 songs\n",
    "        driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")\n",
    "\n",
    "        \n",
    "        break\n",
    "        \n",
    "    except WebDriverException as e: ## Handle the exception\n",
    "        print(\"WebDriverException occurred on retry\", retry + 1)\n",
    "        print(\"Retrying in\", retry_delay, \"seconds...\")\n",
    "        time.sleep(retry_delay)\n",
    "else:\n",
    "    # If all retries fail, handle the exception\n",
    "    print(\"All retries failed. WebDriverException could not be resolved , Please Check your internet connection\")\n",
    "\n",
    "\n",
    "## Define empty lists for teh storage of scrapped data as required.\n",
    "ranks =[]\n",
    "titles=[]\n",
    "authors=[]\n",
    "v_s=[]\n",
    "pubs=[]\n",
    "genre=[]\n",
    "\n",
    "\n",
    "try:\n",
    "    for row in driver.find_elements(By.TAG_NAME,\"tr\"):\n",
    "    # Extract the columns of each row\n",
    "        columns = row.find_elements(By.TAG_NAME,\"td\")\n",
    "    \n",
    "    # Check if the row contains the required data\n",
    "        if len(columns) >= 6:\n",
    "        # Extract the details from the columns\n",
    "            rank = columns[0].text.strip()\n",
    "            title = columns[1].text.strip()\n",
    "            author = columns[2].text.strip()\n",
    "            Volume_sales = columns[3].text.strip()\n",
    "            publisher = columns[4].text.strip()\n",
    "            Genre = columns[5].text.strip()\n",
    "        \n",
    "           ## append the scrapped data     \n",
    "            ranks.append(rank)\n",
    "            titles.append(title)\n",
    "            authors.append(author)\n",
    "            v_s.append(Volume_sales)\n",
    "            pubs.append(publisher)\n",
    "            genre.append(Genre)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "        \n",
    "driver.quit()\n",
    "\n",
    "## Put the data in dictonary \n",
    "data={\n",
    "     \"Title\":titles,\n",
    "     \"Author\":authors,\n",
    "     \"Volume_Sold\":v_s,\n",
    "     \"Publisher\":pubs,\n",
    "     \"Genre\":genre}\n",
    "## display the data in dataframe\n",
    "\n",
    "df=pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfbcd54",
   "metadata": {},
   "source": [
    "# 7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details: A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time E) Ratings F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0bc5e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year_Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,173,741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,251,569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,032,509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>303,562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>262,734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>51,957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>63,995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>208,549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>43,403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>260,211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Title    Year_Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98                          Scream  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "    Runtime Rating       Vote  \n",
       "0    57 min    9.2  2,173,741  \n",
       "1    51 min    8.7  1,251,569  \n",
       "2    44 min    8.1  1,032,509  \n",
       "3    60 min    7.5    303,562  \n",
       "4    43 min    7.6    262,734  \n",
       "..      ...    ...        ...  \n",
       "95   42 min    7.4     51,957  \n",
       "96   50 min    7.8     63,995  \n",
       "97   42 min    8.1    208,549  \n",
       "98   45 min    7.1     43,403  \n",
       "99  572 min    8.6    260,211  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Setup chrome browser in headless mode\n",
    "\n",
    "driver =webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "## Handling WebDriverException taht occured , as the website's load is real slow \n",
    "max_retries = 3 ##no of maximum retries\n",
    "retry_delay = 2 ## retry dealy wait \n",
    "for retry in range(max_retries): \n",
    "    try:\n",
    "        ## open imdb page\n",
    "\n",
    "        driver.get(\"https://www.imdb.com/list/ls095964455/\")\n",
    "        \n",
    "        break\n",
    "        \n",
    "    except WebDriverException as e: ## Handle the exception\n",
    "        print(\"WebDriverException occurred on retry\", retry + 1)\n",
    "        print(\"Retrying in\", retry_delay, \"seconds...\")\n",
    "        time.sleep(retry_delay)\n",
    "else:\n",
    "    # If all retries fail, handle the exception\n",
    "    print(\"All retries failed. WebDriverException could not be resolved , Please Check your internet connection\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## find all elements.\n",
    "items = driver.find_elements(By.XPATH,'//div[@class=\"lister-item mode-detail\"]')\n",
    "## define and empty list for storage\n",
    "imdb_df=[]\n",
    "\n",
    "try:\n",
    "    for item in items: ## iterate through items\n",
    "        imdb={} ## define an empty dictonary \n",
    "        ## scrape the required details\n",
    "        title = item.find_element(By.XPATH,'.//h3[@class=\"lister-item-header\"]//a').text\n",
    "        year_span = item.find_element(By.XPATH,'.//span[@class=\"lister-item-year text-muted unbold\"]').text\n",
    "        genre = item.find_element(By.XPATH,'.//span[@class=\"genre\"]').text\n",
    "        runtime = item.find_element(By.XPATH,'.//span[@class=\"runtime\"]').text\n",
    "        rating = item.find_element(By.XPATH,'.//span[@class=\"ipl-rating-star__rating\"]').text\n",
    "        vote = item.find_element(By.XPATH,'.//p[@class=\"text-muted text-small\"]//span[@name=\"nv\"]').text\n",
    "    \n",
    "    \n",
    "        ## append the scrapped deatils in dictonary \n",
    "        imdb[\"Title\"]=title\n",
    "        imdb[\"Year_Span\"]=year_span\n",
    "        imdb[\"Genre\"]=genre\n",
    "        imdb[\"Runtime\"]=runtime\n",
    "        imdb[\"Rating\"]=rating\n",
    "        imdb[\"Vote\"]= vote\n",
    "        ## append the dictonary to the list\n",
    "        imdb_df.append(imdb)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "    \n",
    "## close the driver\n",
    "driver.quit()\n",
    "\n",
    "## display the list in dataframe\n",
    "df = pd.DataFrame(imdb_df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d956bcdc",
   "metadata": {},
   "source": [
    "# 8. Details of Datasets from UCI machine learning repositories. Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name B) Data type\n",
    "C) Task\n",
    "D) Attribute type E) No of instances F) No of attribute G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e2ad946",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up a chrome browser\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "## Handling WebDriverException\n",
    "max_retries = 3 ##no of maximum retries\n",
    "retry_delay = 2 ## retry dealy wait \n",
    "for retry in range(max_retries): \n",
    "    try:\n",
    "        ## open the given link\n",
    "        driver.get(\"https://archive.ics.uci.edu/\")\n",
    "        \n",
    "        break\n",
    "        \n",
    "    except WebDriverException as e: ## Handle the exception\n",
    "        print(\"WebDriverException occurred on retry\", retry + 1)\n",
    "        print(\"Retrying in\", retry_delay, \"seconds...\")\n",
    "        time.sleep(retry_delay)\n",
    "else:\n",
    "    # If all retries fail, handle the exception\n",
    "    print(\"All retries failed. WebDriverException could not be resolved , Please Check your internet connection\")\n",
    "\n",
    "\n",
    "\n",
    "## find and click All Datasets\n",
    "driver.execute_script(\"arguments[0].click();\",driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "530bbf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## find and click expand all to scrappe the hidden details\n",
    "expand = driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[1]/div/label[2]/div[2]/span[1]')\n",
    "driver.execute_script(\"arguments[0].click();\", expand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "836d606c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>No of Instance</th>\n",
       "      <th>No of attribute</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Life Science</td>\n",
       "      <td>Classification</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>4 Attributes</td>\n",
       "      <td>Real</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Life</td>\n",
       "      <td>Classification</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>13 Attributes</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Social</td>\n",
       "      <td>Classification</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Attributes</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Computer</td>\n",
       "      <td>Classification</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>17 Attributes</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Life</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>20 Attributes</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>PMU-UD</td>\n",
       "      <td>Computer</td>\n",
       "      <td>Classification</td>\n",
       "      <td>5.18K Instances</td>\n",
       "      <td>9 Attributes</td>\n",
       "      <td></td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Undocumented</td>\n",
       "      <td>Other</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>N/A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>BAUM-2</td>\n",
       "      <td>Computer</td>\n",
       "      <td>Classification</td>\n",
       "      <td>1.05K Instances</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Connectionist Bench (Nettalk Corpus)</td>\n",
       "      <td>Other</td>\n",
       "      <td></td>\n",
       "      <td>20.01K Instances</td>\n",
       "      <td>4 Attributes</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>QtyT40I10D100K</td>\n",
       "      <td>Other</td>\n",
       "      <td></td>\n",
       "      <td>3.96M Instances</td>\n",
       "      <td>4 Attributes</td>\n",
       "      <td>Real</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>623 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Dataset_Name     Data Type            Task  \\\n",
       "0                                    Iris  Life Science  Classification   \n",
       "1                           Heart Disease          Life  Classification   \n",
       "2                                   Adult        Social  Classification   \n",
       "3                        Dry Bean Dataset      Computer  Classification   \n",
       "4                                Diabetes          Life                   \n",
       "..                                    ...           ...             ...   \n",
       "618                                PMU-UD      Computer  Classification   \n",
       "619                          Undocumented         Other                   \n",
       "620                                BAUM-2      Computer  Classification   \n",
       "621  Connectionist Bench (Nettalk Corpus)         Other                   \n",
       "622                        QtyT40I10D100K         Other                   \n",
       "\n",
       "       No of Instance No of attribute              Attribute Type  Year  \n",
       "0       150 Instances    4 Attributes                        Real  1988  \n",
       "1       303 Instances   13 Attributes  Categorical, Integer, Real  1988  \n",
       "2    48.84K Instances   14 Attributes        Categorical, Integer  1996  \n",
       "3    13.61K Instances   17 Attributes               Integer, Real  2020  \n",
       "4                       20 Attributes        Categorical, Integer     A  \n",
       "..                ...             ...                         ...   ...  \n",
       "618   5.18K Instances    9 Attributes                              2018  \n",
       "619                                                           N/A     A  \n",
       "620   1.05K Instances                                              2018  \n",
       "621  20.01K Instances    4 Attributes                 Categorical  1954  \n",
       "622   3.96M Instances    4 Attributes                        Real     A  \n",
       "\n",
       "[623 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Define empty lists\n",
    "\n",
    "dataset_name=[]\n",
    "task=[]\n",
    "no_instance=[]\n",
    "no_attribute=[]\n",
    "data_type=[]\n",
    "attribute_type=[]\n",
    "year=[]\n",
    "\n",
    "## Till the next page exists\n",
    "while True:\n",
    "    rows = driver.find_elements(By.XPATH,'//div[@role=\"row\"]') ## find all element conatiners \n",
    "    try:\n",
    "        for row in rows:\n",
    "            ## find dataset name\n",
    "            d_name = row.find_element(By.XPATH,'.//h2[@class=\"truncate text-primary\"]').text\n",
    "            ## task , no of attribute and no of instance present under one column , so extarcting them one by one.\n",
    "            cols = row.find_elements(By.XPATH,'.//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div')\n",
    "            if len(cols)>=4:\n",
    "                t = cols[0].text\n",
    "                inst = cols[2].text\n",
    "                att = cols[3].text\n",
    "                ## append the scrapped data     \n",
    "                task.append(t)\n",
    "                no_instance.append(inst)\n",
    "                no_attribute.append(att)\n",
    "            ## rest of the other features in other column by html design , extracting them one by one        \n",
    "            for trs in row.find_elements(By.TAG_NAME,'tr'):\n",
    "                clms = trs.find_elements(By.TAG_NAME,'td')\n",
    "                if len(clms)>=4:\n",
    "                    d_type = clms[0].text\n",
    "                    a_type = clms[1].text\n",
    "                    y =clms[2].text.split(\"/\")[-1]\n",
    "                ## append the scrapped details accordingly\n",
    "                    data_type.append(d_type)\n",
    "                    attribute_type.append(a_type)\n",
    "                    year.append(y)\n",
    "                \n",
    "           \n",
    "            dataset_name.append(d_name)  \n",
    "    except StaleElementReferenceException: # handle stale element exceptin\n",
    "            pass\n",
    "        \n",
    "        ## find and click next button\n",
    "    next_button = driver.find_element(By.XPATH,'//button[@aria-label=\"Next Page\"]')\n",
    "        # check if next button is enabled\n",
    "    if not next_button.is_enabled():\n",
    "        break\n",
    "        \n",
    "    driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "    \n",
    "        #time.sleep(2)\n",
    "    \n",
    "    \n",
    "## close the drievr\n",
    "driver.quit()    \n",
    "\n",
    "## define the dictonary with scrapped data\n",
    "data={\"Dataset_Name\":dataset_name,\n",
    "     \"Data Type\":data_type,\n",
    "     \"Task\":task,\n",
    "     \"No of Instance\":no_instance,\n",
    "     \"No of attribute\":no_attribute,\n",
    "     \"Attribute Type\":attribute_type,\n",
    "     \"Year\":year\n",
    "     }\n",
    "\n",
    "## Display the data in dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74872984",
   "metadata": {},
   "source": [
    "# 9. Scrape the details of Data science recruiters                                                \n",
    "Url= https://www.naukri.com/hr-recruiters-consultants \n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "B) Designation\n",
    "C)Company\n",
    "D)Skills they hire for \n",
    "E) Location\n",
    "\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and click on search. All this should be done through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5aab6b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception raised and Handled\n",
      "1021 Out of 15506 HR Jobs are scrapped\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Dsignation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Opening For Management Trainee / Executive - HR</td>\n",
       "      <td></td>\n",
       "      <td>Sahajanand Medical Technologies</td>\n",
       "      <td>Mumbai (All Areas)</td>\n",
       "      <td>Recruitment\\nTalent Acquisition\\nTraining\\nMIS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiring Freshers : HR Executive: Recruiter-Guru...</td>\n",
       "      <td>Executive: Recruiter-Gurugram : ACS</td>\n",
       "      <td>Advance Career Solutions</td>\n",
       "      <td>Gurgaon/ Gurugram, Haryana</td>\n",
       "      <td>communication skills\\nRecruitment\\nHiring\\nAcd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Executive/ Assistant Manager HR Generalist - P...</td>\n",
       "      <td>Generalist - Pune ( Dress Code )</td>\n",
       "      <td>OASIS</td>\n",
       "      <td>Pune, Maharashtra(Koregaon Park)</td>\n",
       "      <td>hr generalist activities\\nHR Information Syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assistant Manager - HR (Field Level Recruitment)</td>\n",
       "      <td>(Field Level Recruitment)</td>\n",
       "      <td>Muthoot Microfin</td>\n",
       "      <td>Bhubaneswar, Odisha, Hubli, Karnataka, Sambalp...</td>\n",
       "      <td>NBFC\\nrecruitment\\nMass Hiring\\nBulk Hiring\\nL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Recruiter</td>\n",
       "      <td>Symphoni Hr</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Recruitment\\nExit formalities\\nTalent acquisit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Executive</td>\n",
       "      <td>Manpower Resources India</td>\n",
       "      <td>Jamshedpur, Jharkhand</td>\n",
       "      <td>HR Generalist Activities\\nplant hr\\nHR Operati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>HR Exec/ Human Resources Executive/ Lead HR/ B...</td>\n",
       "      <td>Exec/ Human Resources Executive/ Lead</td>\n",
       "      <td>Selectica International Solutions Llp</td>\n",
       "      <td>Thane, Maharashtra, Pune, Maharashtra, Mumbai ...</td>\n",
       "      <td>BPO Hiring\\nHR\\nCampus hiring\\nBPO\\nBulk\\nTale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>Executive - HR &amp; Compliance</td>\n",
       "      <td>&amp; Compliance</td>\n",
       "      <td>Peoplepro Management Services</td>\n",
       "      <td>Kolkata, Durgapur, West Bengal, Howrah, West B...</td>\n",
       "      <td>Payroll Management\\nLaw\\nGeneralist Activities...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>Urgent requirement For HR Executives</td>\n",
       "      <td>Executives</td>\n",
       "      <td>Kamms Management Consultants</td>\n",
       "      <td>Chennai, Tamil Nadu</td>\n",
       "      <td>RECRUITER\\nResource\\nManagement\\nHrsd\\nRequire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>HR Executive- Payroll</td>\n",
       "      <td>Executive- Payroll</td>\n",
       "      <td>Megma Services</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>HR\\nVerification\\nProcess\\nReconciliation\\nHrs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1020 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Name  \\\n",
       "0       Opening For Management Trainee / Executive - HR   \n",
       "1     Hiring Freshers : HR Executive: Recruiter-Guru...   \n",
       "2     Executive/ Assistant Manager HR Generalist - P...   \n",
       "3      Assistant Manager - HR (Field Level Recruitment)   \n",
       "4                                          HR Recruiter   \n",
       "...                                                 ...   \n",
       "1015                                       HR Executive   \n",
       "1016  HR Exec/ Human Resources Executive/ Lead HR/ B...   \n",
       "1017                        Executive - HR & Compliance   \n",
       "1018               Urgent requirement For HR Executives   \n",
       "1019                              HR Executive- Payroll   \n",
       "\n",
       "                                   Dsignation  \\\n",
       "0                                               \n",
       "1         Executive: Recruiter-Gurugram : ACS   \n",
       "2            Generalist - Pune ( Dress Code )   \n",
       "3                   (Field Level Recruitment)   \n",
       "4                                   Recruiter   \n",
       "...                                       ...   \n",
       "1015                                Executive   \n",
       "1016   Exec/ Human Resources Executive/ Lead    \n",
       "1017                             & Compliance   \n",
       "1018                               Executives   \n",
       "1019                       Executive- Payroll   \n",
       "\n",
       "                                    Company  \\\n",
       "0           Sahajanand Medical Technologies   \n",
       "1                  Advance Career Solutions   \n",
       "2                                     OASIS   \n",
       "3                          Muthoot Microfin   \n",
       "4                               Symphoni Hr   \n",
       "...                                     ...   \n",
       "1015               Manpower Resources India   \n",
       "1016  Selectica International Solutions Llp   \n",
       "1017          Peoplepro Management Services   \n",
       "1018           Kamms Management Consultants   \n",
       "1019                         Megma Services   \n",
       "\n",
       "                                               Location  \\\n",
       "0                                    Mumbai (All Areas)   \n",
       "1                            Gurgaon/ Gurugram, Haryana   \n",
       "2                      Pune, Maharashtra(Koregaon Park)   \n",
       "3     Bhubaneswar, Odisha, Hubli, Karnataka, Sambalp...   \n",
       "4                                                Remote   \n",
       "...                                                 ...   \n",
       "1015                              Jamshedpur, Jharkhand   \n",
       "1016  Thane, Maharashtra, Pune, Maharashtra, Mumbai ...   \n",
       "1017  Kolkata, Durgapur, West Bengal, Howrah, West B...   \n",
       "1018                                Chennai, Tamil Nadu   \n",
       "1019                                        Delhi / NCR   \n",
       "\n",
       "                                                 Skills  \n",
       "0     Recruitment\\nTalent Acquisition\\nTraining\\nMIS...  \n",
       "1     communication skills\\nRecruitment\\nHiring\\nAcd...  \n",
       "2     hr generalist activities\\nHR Information Syste...  \n",
       "3     NBFC\\nrecruitment\\nMass Hiring\\nBulk Hiring\\nL...  \n",
       "4     Recruitment\\nExit formalities\\nTalent acquisit...  \n",
       "...                                                 ...  \n",
       "1015  HR Generalist Activities\\nplant hr\\nHR Operati...  \n",
       "1016  BPO Hiring\\nHR\\nCampus hiring\\nBPO\\nBulk\\nTale...  \n",
       "1017  Payroll Management\\nLaw\\nGeneralist Activities...  \n",
       "1018  RECRUITER\\nResource\\nManagement\\nHrsd\\nRequire...  \n",
       "1019  HR\\nVerification\\nProcess\\nReconciliation\\nHrs...  \n",
       "\n",
       "[1020 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup the chrome browser in headless mode\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "## Load the given uRL.\n",
    "\n",
    "## Handling WebDriverException\n",
    "max_retries = 3 ##no of maximum retries\n",
    "retry_delay = 2 ## retry dealy wait \n",
    "for retry in range(max_retries): \n",
    "    try:\n",
    "        ## open the given link\n",
    "        driver.get(\"https://www.naukri.com/hr-recruiters-consultants\")\n",
    "        \n",
    "        break\n",
    "        \n",
    "    except WebDriverException as e: ## Handle the exception\n",
    "        print(\"WebDriverException occurred on retry\", retry + 1)\n",
    "        print(\"Retrying in\", retry_delay, \"seconds...\")\n",
    "        time.sleep(retry_delay)\n",
    "else:\n",
    "    # If all retries fail, handle the exception\n",
    "    print(\"All retries failed. WebDriverException could not be resolved , Please Check your internet connection\")\n",
    "\n",
    "## Define empty lists for storage.\n",
    "\n",
    "names=[]\n",
    "designations=[]\n",
    "company_names=[]\n",
    "skills=[]\n",
    "locations=[]\n",
    "\n",
    "while len(names)<=1000:\n",
    "    ## Wait till the driver finds first job element\n",
    "    wait = WebDriverWait(driver, 5)\n",
    "    wait.until(EC.presence_of_element_located((By.XPATH,'//article[@class=\"jobTuple\"]')))\n",
    "    \n",
    "    ## Select all jobs. \n",
    "    jobs = driver.find_elements(By.XPATH,'//article[@class=\"jobTuple\"]') \n",
    "    \n",
    "    ## Scrape all the required details\n",
    "    try:  \n",
    "        for job in jobs:\n",
    "            try: \n",
    "                name = job.find_element(By.XPATH,'.//div[@class=\"info fleft\"]//a').text\n",
    "            except:\n",
    "                name='-'\n",
    "            try: \n",
    "                des = job.find_element(By.XPATH,'.//div[@class=\"info fleft\"]//a').text.split('HR')[1]\n",
    "            except:\n",
    "                des='-'\n",
    "            try:\n",
    "                company = job.find_element(By.XPATH,'.//div[@class=\"companyInfo subheading\"]//a').text\n",
    "            except:\n",
    "                comapny='-'\n",
    "            try:\n",
    "                loc = job.find_element(By.XPATH,'.//li[@class=\"fleft br2 placeHolderLi location\"]').text\n",
    "            except:\n",
    "                loc='-'\n",
    "            try:\n",
    "\n",
    "                skill = job.find_element(By.XPATH,'.//ul[@class=\"tags has-description\"]').text.strip('/n')\n",
    "            except:\n",
    "                skill='-'\n",
    "            ## Append all the scrapped details\n",
    "            names.append(name) \n",
    "            company_names.append(company)\n",
    "            designations.append(des)\n",
    "            locations.append(loc)\n",
    "            skills.append(skill)\n",
    "            \n",
    "    ## If exception rise : continue\n",
    "    except NoSuchElementException:\n",
    "         continue\n",
    "    ## try to find Next button on this page.\n",
    "    try:\n",
    "        ## Wait till next button is found\n",
    "        wait_2 = WebDriverWait(driver, 10)\n",
    "    \n",
    "        wait_2.until(EC.presence_of_element_located((By.XPATH,'//a[@class=\"fright fs14 btn-secondary br2\"]')))\n",
    "        ## Click on next button\n",
    "        next_button = driver.find_element(By.XPATH,'//a[@class=\"fright fs14 btn-secondary br2\"]')\n",
    "        driver.execute_script(\"arguments[0].click();\", next_button)   \n",
    "    ## If Exception rises , try again    \n",
    "    except NoSuchElementException:\n",
    "        max_retries = 2\n",
    "        retry_delay = 2\n",
    "        for retry in range(max_retries):\n",
    "            next_button = driver.find_element(By.XPATH,'//a[@class=\"fright fs14 btn-secondary br2\"]')\n",
    "    \n",
    "            if not next_button.is_enabled():\n",
    "                break\n",
    "    \n",
    "            driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "            time.sleep(2)\n",
    "\n",
    "## Print no of jobs scarpped.\n",
    "try:\n",
    "    elements_displayed = driver.find_element(By.XPATH,'//div[@class=\"sortAndH1Cont\"]').text.split()\n",
    "    print(elements_displayed[2],\"Out of\",elements_displayed[4],\"HR Jobs are scrapped\" )\n",
    "\n",
    "# If exception rises, wait yill driver finds the element and then print\n",
    "except NoSuchElementException:\n",
    "    wait_3 = WebDriverWait(driver, 10)\n",
    "    \n",
    "    wait_3.until(EC.presence_of_element_located((By.XPATH,'//div[@class=\"sortAndH1Cont\"]')))\n",
    "    \n",
    "    elements_displayed = driver.find_element(By.XPATH,'//div[@class=\"sortAndH1Cont\"]//div[@class=\"h1-wrapper\"]').text.split()\n",
    "\n",
    "    print(\"Exception raised and Handled\")\n",
    "    print(elements_displayed[0],\"Out of\",elements_displayed[4],\"HR Jobs are scrapped\" )\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Store the scrapped details in dictonary\n",
    "jobs_df={\"Name\":names,\n",
    "         \"Dsignation\" : designations,\n",
    "        \"Company\":company_names,\n",
    "         \n",
    "        \"Location\":locations,\n",
    "        \"Skills\":skills}\n",
    "\n",
    "## Display in dataframe\n",
    "df = pd.DataFrame(jobs_df)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
